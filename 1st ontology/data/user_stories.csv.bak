StoryID,UserStory
US1,"Michael is driving home after a long workday, traveling on a highway for over two hours. As night falls, his PostureState begins to change—his Head Position shows nodding patterns, and the vehicle's Detection methodologies using Driver-facing Visual sensors detect reduced Eye tracking metrics and longer blink durations. The Physiological Sensors and Behavioral analysis systems classify these patterns as indicators of Drowsiness and Fatigue, both subclasses of InattentionState within the CognitiveState category of Driver parameters. The Vehicle system (HMI) responds by modifying its Visual feedback—gradually increasing the brightness of the Display Types and adjusting the contrast of Visual Elements to improve visibility. When Michael's Head Position nodding becomes more frequent, the Tactile feedback system activates Haptic Alerts through the steering wheel, while the Audio feedback system adjusts Auditory Displays to increase the volume of navigation prompts. The Dialog Design component generates a gentle voice alert with the Message Structure: 'Would you like to find a rest area nearby?' with simplified Visual Elements appearing on the center display. When Vehicle Data Analysis detects that Michael passes a highway exit without signaling—behavior that deviates from his normal DrivingBehaviour pattern—the Force Feedback in the steering wheel intensifies according to Adaptivity Parameters specific to InattentionState detection, and a more prominent visual alert appears, showing the distance to the next rest stop."
US2,"Elena is navigating through dense city traffic during rush hour. The Environment factors include moderate weather conditions (rain) and traffic conditions (high congestion). The road type is 'city' with multiple vehicles changing lanes unpredictably, pedestrians creating potential for DistractionState, and construction signs requiring immediate attention. The Pressure Sensors detect that Elena's Steering wheel grip tightens significantly, while Physiological Sensors including Heart rate monitoring (ECG) show increased cardiovascular activity. Eye tracking data from Driver-facing Visual sensors show her eye movements have become rapid and scattered. The Contextual Analysis system incorporates Environment-based Factors including Road complexity analysis and Traffic density estimation to register high complexity. The combination of Physiological Sensors and Behavioral analysis indicates Elena is experiencing high cognitive load, a specific CognitiveState with elevated stress (EmotionalState). The Vehicle system (HMI) responds by modifying Visual feedback—simplifying Display Types and hiding non-essential Visual Elements. It adjusts its Dialog Design to pause incoming notifications and reduces Visual Elements in the navigation display to only critical information with increased contrast. The ADAS system's Lane keeping assist becomes more active according to Driver state adaptation rules, providing subtle steering support, while the Audio feedback system lowers background Audio Parameters and provides clear, concise Wording using a calmer voice tone."
US3,"Daniel has PersonalityFactor traits that include Aggressive driving tendency and low conscientiousness within his Big Five Personality traits profile. He is currently stuck in traffic conditions (high congestion) on a road type 'city' due to construction. The vehicle's Detection methodologies employ multiple approaches to monitor his state: Steering Behavior Analysis detects harder than normal acceleration with irregular Steering smoothness metrics, Pedal Control Analysis shows forceful Braking behavior analysis, Pressure Sensors detect increased Steering wheel grip sensors pressure, and Speech recognition systems in the Microphones detect verbal expressions of anger. The Contextual Analysis confirms Environment factors that typically trigger Frustration (a DiscreteEmotiveState within EmotionalState): traffic conditions (high congestion), journey context deviating significantly from expected Time-on-task measurement, and multiple sudden stops requiring Braking behavior analysis. The system accesses Daniel's driver profile, which includes his PersonalityFactor traits and typical DrivingBehaviour patterns. The Vehicle system (HMI) responds by adapting Visual feedback to display an alternate route option with an accurate Time-based Factors estimate, using calming Visual Elements with blue color schemes designed to reduce Arousal levels in the ContinuousEmotiveState dimension. The Audio feedback suggests switching to Daniel's preferred Auditory Displays, and the vehicle's environmental systems adjust cabin temperature. When Speed Management Analysis detects aggressive acceleration movements, the Tactile feedback in the accelerator pedal provides Force Feedback with gentle resistance, encouraging smoother DrivingBehaviour."
US4,"Martha is 78 years old and drives a vehicle equipped with adaptive Vehicle system (HMI) components. She is traveling to visit family in an unfamiliar journey context with road type 'suburban.' As she drives, the weather conditions transition from 'sun' to 'fog,' reducing visibility as detected by Environmental condition assessment sensors. Martha's driver profile indicates age-related factors including slightly slower reaction times in CognitiveState and a preference for simplified Display Types with larger Visual Elements. The vehicle's Driver-facing Visual sensors detect that Martha is frequently alternating Eye tracking between the navigation display and the road, with increased eye fixation time on the interface. Steering Behavior Analysis shows increased Micro-adjustments frequency analysis and Steering entropy calculation, indicating increased attention demands. The Contextual Analysis registers the changing Environment-based Factors and unfamiliar road type. The Vehicle system (HMI) responds by modifying Visual feedback—increasing the size of Visual Elements and enhancing contrast on Display Types. The Audio feedback system adjusts Audio Parameters to provide earlier voice prompts with clearer Dialog Design for upcoming turns. The Wording system employs simpler Message Structure with increased comprehensibility. The ADAS Lane keeping assist becomes more sensitive according to Driver state adaptation rules, providing subtle guidance, while Haptic Alerts in the steering wheel gently notify Martha when Lane detection systems indicate drift toward boundaries."
US5,"Alex is commuting to work in a vehicle with Level 3 autonomy capabilities. The journey begins on a road type 'highway' in autonomous mode, but construction ahead will require manual driving. The Road-facing Cameras and Contextual Analysis detect the upcoming transition zone through Environmental condition assessment, and the Vehicle system (HMI) prepares Alex for the handover. The vehicle's Detection methodologies assess Alex's current state through Cameras and Physiological Sensors. The DistractionState monitoring classifies Alex as engaged in 'Non-driving related (has type)' activities (reading emails on the center display) and PostureState analysis indicates a relaxed body position with low vigilance in CognitiveState. Ten minutes before the handover point, the Vehicle system (HMI) begins a sequenced Multimodal Integration protocol. The Visual feedback subtly shifts ambient lighting, and the Audio feedback provides a gentle auditory notification about the upcoming control transition. The Display Types transition from non-driving content to a simplified driving interface with highlighted Visual Elements showing road information. A dedicated Visual feedback element shows a countdown timer alongside Lane detection visualization of the road ahead. As the handover point approaches, the PostureState support systems gradually adjust the seat position to encourage a more attentive Body Posture, and Haptic Alerts in the seat provide Tactile feedback cues. The system continuously monitors Eye tracking, Head Position, and PostureState to confirm readiness, adjusting the Interaction Timing of the handover based on these indicators of CognitiveState and attention levels according to Trust calibration mechanisms designed for smooth transitions."
US6,"Dr. Rodriguez leads a research team evaluating driver experiences with a new Vehicle system (HMI). Their methodology combines objective Detection methodologies with subjective Self-measures through standardized Questionnaires. Today, they're working with Wei, a volunteer driver participating in their simulator-based study. Wei completes pre-driving Questionnaires including Big Five Personality traits assessment and Aggressive driving tendency metrics to establish his PersonalityFactor profile. He then drives through a simulated environment while the system collects data across multiple Driver parameters. During challenging scenarios involving varying traffic conditions and weather conditions, the simulator introduces controlled DistractionState triggers and monitors CognitiveState responses. After each driving segment, the system prompts Wei with NASA-TLX Questionnaires to self-report mental workload, frustration, and effort levels. These Self-measures are time-stamped and correlated with physiological data from Electrodermal activity and Skin conductance measurement (EDA), Heart rate monitoring (ECG), and Electroencephalogram (EEG) recordings. The system also administers specific Measures rating user satisfaction with different Tactile feedback, Audio feedback, and Visual feedback elements. The research team uses this integrated dataset to calibrate Driver state adaptation rules, refine Trust calibration mechanisms, and validate Regulation strategies for vehicle systems. By comparing subjective ratings with objective sensor data, they identify gaps between perceived and actual driver states, which helps optimize Cross-modal congruence in future Multimodal Integration designs."
US7,"Sophia is driving on a long journey through varied Environment factors. Her route takes her from urban areas through rural highways, exposing her to multiple road conditions ('even' to 'uneven') and different daytime conditions transitioning from 'day time' to 'night time' as her journey progresses. The season is spring, with air quality changing from 'clean' to 'pollution' as she approaches an industrial area, and eventually to 'pollen' as she passes through agricultural regions. The vehicle's Detection methodologies continually monitor environmental changes through Road-facing Cameras and sensors measuring air quality. These Environmental condition assessment systems detect how different combinations of Environment factors affect both the vehicle's sensing capabilities and Sophia's Driver parameters. For instance, when air quality shifts to 'pollen' levels, Biological Sensors detect subtle changes in Sophia's Respiration sensors data, potentially indicating mild discomfort. As road conditions change from 'even' to 'uneven,' Steering Behavior Analysis shows increased Micro-adjustments frequency analysis while Seat occupancy sensors detect changes in Body Posture and Trunk position as Sophia unconsciously adjusts to maintain stability. When daytime conditions shift to 'night time' while simultaneously encountering weather conditions changing to light 'rain,' Road complexity analysis indicates a significant increase in driving demands. The Vehicle system (HMI) responds with coordinated adaptations across multiple systems. The climate control adjusts to filter air when air quality deteriorates, while Display Types modify brightness and contrast based on daytime conditions. Lane keeping assist sensitivity increases during the combination of 'night time' and 'rain' conditions, while Speed violation tendency measurement triggers subtle interventions when the system detects Sophia unconsciously exceeding safe speeds for current road conditions. Throughout these changes, Trip duration tracking helps the system recommend appropriate rest breaks based on cumulative Environmental condition assessment complexity over time."
US8,"Wei-Lin is a certification specialist evaluating a new vehicle's HMI systems against Regulation strategies and User Experience Factors standards. Her team uses a systematic approach to assess compliance with safety requirements while simultaneously measuring user acceptance and Trust calibration mechanisms. Today, Wei-Lin is conducting a standardized assessment of how the vehicle's ADAS features interact with its Vehicle system (HMI) components. The test scenario begins with a driver operating the vehicle while the evaluation system monitors all feedback channels. When the Lane keeping assist detects lane departure, it activates, providing Force Feedback through the steering wheel. Simultaneously, the Visual feedback system displays an alert using standardized Visual Elements, while Audio feedback provides a warning tone according to Regulation strategies for warning prioritization. Wei-Lin's team measures several aspects of this interaction: the Urgency-based timing of alerts relative to the lane departure event, the Cross-modal congruence between visual, audio, and tactile warnings, and the effectiveness of Trust calibration mechanisms in conveying appropriate confidence levels to the driver. They assess whether the system's multimodal approach effectively communicates both what is happening (Lane keeping assist activation) and why it's occurring (lane departure). The team also evaluates adaptations for different driver states. They simulate a driver experiencing Confusion (a DiscreteEmotiveState) and measure how the system adjusts its Dialog Design and Message Structure to provide clearer guidance. Similarly, they test scenarios where a driver exhibits Speed violation tendency to assess how the system balances safety interventions with user acceptance according to User Experience Factors principles. Throughout testing, Wei-Lin's team documents compliance with specific Regulation strategies while also conducting User Experience Factors assessments to ensure interventions maintain appropriate trust levels without causing frustration or system disregard."
GEN,This is a general reference for competency questions about HMI Ontology systems without a specific user story. These questions address fundamental aspects of the ontology structure and relationships.
